<!-- vim: foldmethod=marker
-->
<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>はじめてのパターン認識 勉強メモ</title>

		<meta name="description" content="はじめてのパターン認識 3章">
		<meta name="author" content="2GMon">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="../css/reveal.min.css">
		<link rel="stylesheet" href="../css/theme/default.css" id="theme">
		<link rel="stylesheet" href="../css/2gmon.css">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="../lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = '../css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="../lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
                <section>
                    <h3>はじめてのパターン認識</h3>
                    <h3>3章</h3>
                    <p>
                    <small>Created by <a href="https://twitter.com/2GMon">2GMon</a></small>
                    </p>
                </section>

                <section>
                    <h3>話の流れ</h3>

                    <ul>
                        <li>ベイズの識別規則</li>
                        <li>ROC曲線</li>
                    </ul>
                </section>

                <section>
                    <p>観測データ${\bf x}$と所属するクラスの間に確率分布が仮定される識別問題について考える</p>
                    <p>ここでは、最大事後確率基準に基づくベイズの識別規則を定義し、ベイズの識別規則が誤り率最小になることを示す</p>
                </section>

                <section>
                    <h3>最大事後確率基準</h3>
                    <p>観測データを${\bf x}$、識別クラスを$C_i ; (i = 1, \cdots, K)$とする</p>
                    <p>ベイズの識別規則は、以下で定義される事後確率が最も大きなクラスに観測データを分類する
                    $$ P(C_i|{\bf x}) = \frac{p({\bf x}|C_i)}{p({\bf x})} P(C_i) = 修正項 * 事前確率 $$</p>
                </section>

                <section>
                    <p>クラス$C_i$と$C_j$の識別境界は、事後確率が等しくなるところである
                    <span style="font-size: 80%">
                        $$ P(C_i|{\bf x}) = \frac{p({\bf x}|C_i)P(C_i)}{p({\bf x})} = \frac{p({\bf x}|C_j)P(C_j)}{p({\bf x})} = P(C_j|{\bf x}) $$
                    </span></p>
                    <p>$p({\bf x})$は大小比較に関係ないので、識別規則は以下のようになる
                    $$ 識別クラス = argmax_i p({\bf x}|C_i)P(C_i) $$ </p>
                </section>

                <section>
                    <h3>尤度比</h3>
                    <p>決定境界は
                    <span style="font-size: 80%">
                        $$ P(C_i|{\bf x}) = \frac{p({\bf x}|C_i)P(C_i)}{p({\bf x})} = \frac{p({\bf x}|C_j)P(C_j)}{p({\bf x})} = P(C_j|{\bf x}) $$
                    </span>なので、尤度と事前確率の積を比較して識別クラスを決定することもできる
                    <span style="font-size: 80%">
                    $$
                      p({\bf x}|C_i)P(C_i) \left \{
                        \begin{array}{l}
                          > \\
                          <
                        \end{array}
                      \right \}
                      p({\bf x}|C_i)P(C_i) \left \{
                        \begin{array}{l}
                          => C_i \\
                          => C_j
                        \end{array}
                      \right .
                    $$
                    </span>
                    更に変形して尤度比でも識別規則を構成できる
                    <span style="font-size: 80%">
                    $$
                      \frac{p({\bf x}|C_i)}{p({\bf x}|C_j)} \left \{
                        \begin{array}{l}
                          > \\
                          <
                        \end{array}
                      \right \}
                      \frac{P(C_j)}{P(C_i)} \left \{
                        \begin{array}{l}
                          => C_i \\
                          => C_j
                        \end{array}
                      \right .
                    $$
                    </span>
                    </p>
                </section>

                <section>
                    <p>2クラス$(\{C_1, C_2\})$識別問題を用いて、ベイズの識別規則が誤り率を最小にすることを示す</p>
                    <p>ベイズの識別規則のもとでの誤り率$\epsilon({\bf x})$は事後確率の小さい方になり、条件付きベイズ誤り率という
                    $$ \epsilon({\bf x}) = min [P(C_1|{\bf x}), P(C_2|{\bf x})]$$</p>
                    <p>クラス$C_1$に識別される領域を$R_1$、クラス$C_2$に識別される領域を$R_2$とすると、
                    ベイズ誤り率は領域$R_1$、$R_2$における条件付きベイズ誤り率の期待値として表される
                    $$ \epsilon^* = E\{\epsilon({\bf x})\} = \int_{R_1 + R_2} \epsilon({\bf x})p({\bf x}) d{\bf x} $$
                    </p>
                </section>

                <section>
                    <span style="font-size: 85%">
                    $$ \begin{align} \epsilon^* & = E\{\epsilon({\bf x})\} = \int_{R_1 + R_2} \epsilon({\bf x})p({\bf x}) d{\bf x} \\
                    & = \int_{R_1 + R_2} min [P(C_1|{\bf x}), P(C_2|{\bf x})] p({\bf x}) d{\bf x} \\
                    & = \int_{R_1 + R_2} min [\frac{p({\bf x}|C_1)P(C_1)}{p({\bf x})}, \frac{p({\bf x}|C_2)P(C_2)}{p({\bf x})}] p({\bf x}) d{\bf x} \\
                    & = \int_{R_1 + R_2} min [p({\bf x}|C_1)P(C_1), p({\bf x}|C_2)P(C_2)] d{\bf x} \\
                    & = \int_{R_1 + R_2} (p(C_1, {\bf x} \in R_2) + p(C_2, {\bf x} \in R_1)) \\
                    & = \int_{R_2} p({\bf x}|C_1)P(C_1)d{\bf x} + \int_{R_1} p({\bf x}|C_2)P(C_2)d{\bf x} \end{align}$$
                    </span>
                </section>

                <section>
                    <p>前項の積分の様子を図示する</p>
                    <p>識別境界は$\Theta$にあるので積分は図の薄い網掛けの面積に対応し、識別境界が$\Theta^*$にずれると
                    ベイズ誤り率は濃い網掛けの面積だけ増加するので、ベイズの識別規則は誤り率最小となる</p>
                    <img src="./1.jpg" width="480px">
                </section>

                <section>
                    <p>クラスを識別するときに、誤りを犯すことによって発生する危険性は、クラス間で対象であるとは限らない</p>
                    <p>そこで、危険性を加味した識別規則を構成するために、損失$L_{ij}$を導入する</p>
                    <p>$L_{ij}$は真のクラスが$C_j$のとき$C_i$と識別することによって被る損失を表す</p>
                    <p>$L_{ij}$を要素とする$K × K$行列を損失行列という</p>
                </section>

                <section>
                    <p>観測データ${\bf x}$をクラス$C_i$と識別した時の損失は
                    $$ r(C_i|{\bf x}) = \sum_{k = 1}{K} L_{ik} P(C_k|{\bf x}) $$
                    なので、識別規則は以下のようになる
                    $$ 識別クラス = argmin_i r(C_i|{\bf x}) $$</p>
                    <p>クラス1, 2に識別される領域全体にわたる損失の期待値は、先ほどと同様の積分によって
                    <span style="font-size: 85%">
                    $$ \begin{align} r & = E\{r({\bf x})\} \\
                    & = \int_{R_1} (L_{11}p({\bf x}|C_1)P(C_1) + L_{12}p({\bf x}|C_2)P(C_2)) d{\bf x} \\
                    & + \int_{R_1} (L_{21}p({\bf x}|C_1)P(C_1) + L_{22}p({\bf x}|C_2)P(C_2)) d{\bf x} \end{align} $$
                    </span></p>
                </section>

                <section>
                    <p>損失の期待値が最小となる識別境界は、各入力${\bf x}$に対して被積分項が小さな方に判断されるような領域$R_1$,$R_2$
                    を定めることにより得られるので
                    <span style="font-size: 80%">
                    $$ L_{11}p({\bf x}|C_1)P(C_1) + L_{12}p({\bf x}|C_2)P(C_2) 
                    \left\{\begin{array}{l}
                      < \\
                      >
                    \end{array}\right\} \\
                    L_{21}p({\bf x}|C_1)P(C_1) + L_{22}p({\bf x}|C_2)P(C_2)
                    \left\{\begin{array}{l}
                      => C_1 \\
                      => C_2
                    \end{array}\right\}
                    $$</span></p>
                </section>

                <section>
                    <p>損失最小基準により、ベイズの識別境界が移動する様子を以下に示す</p>
                    <img src="2.jpg" width="640px">
                </section>

                <section>
                    <p>条件付きベイズ誤り率は事後確率の小さい方$\epsilon({\bf x}) = min [P(C_1|{\bf x}), P(C_2|{\bf x})]$で与えられるので、
                    事後確率が等しい、ベイズ境界での誤り率は1/2となる</p>
                    <p>誤り率が大きい時に判断を避けることをリジェクトといい、以下に誤り率が$\epsilon({\bf x}) \geq t$となる領域を
                    リジェクトする場合を示す</p>
                    <img src="3.jpg" width="480px">
                </section>

                <section>
                    <h3>ROC曲線</h3>

                    <p>ベイズの識別規則が誤り率最小であることを示したが、クラスの分布に重なりがあれば、必ず誤りが生じる</p>
                    <p>識別性能の指標にベイズ誤り率があるが、事前確率・尤度・識別境界を知る必要がある</p>
                    <p>このような情報を必要としない指標にROC曲線がある</p>
                </section>

                <section>
                    <p>ROC曲線はFalse Positive率とTrue Positive率の関係をグラフにしたものである</p>
                    <table border="2">
                        <tr><td colspan="2" rowspan="2"></td><td colspan="2">識別クラス</td></tr>
                        <tr><td>p</td><td>n</td></tr>
                        <tr><td rowspan="2">真のクラス</td><td>p</td><td>True Positive</td><td>False Negative</td></tr>
                        <tr><td>n</td><td>False Positive</td><td>True Negative</td></tr>
                    </table>
                    <br />
                    <p>False Positiveは本来偽であるものの中のみで、True Positiveは本来真であるものの中のみで計算されるので、
                    真のクラスのデータ数と偽のクラスのデータ数に大きな差があってもROC曲線は影響を受けない</p>
                </section>

                <section>
                    <p>左図の識別境界を動かした時に求められるROC曲線を右図に示す</p>
                    <table>
                        <tr><td><img src="4.jpg" width="400px"></td><td><img src="5.jpg" width="450px"></td></tr>
                    </table>
                </section>

                <section>
                    <p>ROC曲線はクラス間の重なりが少ないほど左上方向にシフトする</p>
                    <p>ROC曲線の下側の面積をAUCといい、識別器の性能を表す評価尺度として使われている</p>
                    <p>完全な識別器のROC曲線は原点から(0,1)を通り(1, 1)を結ぶ直線となりAUCは1になる</p>
                    <p>原点と(1,1)を結ぶ直線はランダムな識別器のROC曲線となりAUCは0.5になる</p>
                </section>

                <section>
                    <p>ROC曲線が得られた後、動作点(TPとFPの組み合わせ)を選ぶために最小損失識別規則を用いる</p>
                    <p><span style="font-size: 80%">
                    $$ L_{11}p({\bf x}|C_1)P(C_1) + L_{12}p({\bf x}|C_2)P(C_2)
                    \left\{\begin{array}{l}
                      < \\
                      >
                    \end{array}\right\} \\
                    L_{21}p({\bf x}|C_1)P(C_1) + L_{22}p({\bf x}|C_2)P(C_2)
                    \left\{\begin{array}{l}
                      => C_1 \\
                      => C_2
                    \end{array}\right\}
                    $$</span>より、$L_{11}=L_{22}=0$と仮定して、尤度比に変形すれば
                    <span style="font-size: 80%">
                    $$ \frac{p({\bf x}|p^*)}{p({\bf x}|n^*)}
                    \left\{\begin{array}{l}
                      > \\
                      <
                    \end{array}\right\}
                    \frac{L_{12} P(n^)}{L_{21}P(p^*)}
                    \left\{\begin{array}{l}
                      => p \\
                      => n
                    \end{array}\right\}
                    $$</span></p>
                </section>

                <section>
                    <p>損失の期待値を$r$とすれば、
                    <span style="font-size: 85%">
                    $$ \begin{align} r & = E\{r({\bf x})\} \\
                    & = \int_{R_1} (L_{11}p({\bf x}|C_1)P(C_1) + L_{12}p({\bf x}|C_2)P(C_2)) d{\bf x} \\
                    & + \int_{R_1} (L_{21}p({\bf x}|C_1)P(C_1) + L_{22}p({\bf x}|C_2)P(C_2)) d{\bf x} \end{align} $$
                    </span>より、
                    <span style="font-size: 85%">
                    $$ \begin{align} r & = \int_{R_1} [L_{12}p({\bf x}|n^*)P(n^*)]dx + \int_{R_2} [L_{21}p({\bf x}|p^*)P(p^*)]dx \\
                    & = L_{12}P(n^*)\epsilon_2 + L_{21}P(p^*)\epsilon_1 \end{align} $$
                    </span></p>
                </section>

                <section>
                    <p><span style="font-size: 85%">
                    $$ \begin{align} 1 - \epsilon_1 & = \frac{L_{12}P(n^*)}{L_{21}P(p^*)} \epsilon_2 + (1 - \frac{r}{L_{21}P(p^*)}) \\
                    & = \alpha \epsilon_2 + h(r) \end{align} $$
                    </span></p>
                    <p>よって、事前確率と損失が既知であれば直選のかたむき$\alpha$が決まり、損失の期待値$r$により切片が変化する等損失直線が得られる</p>
                </section>

                <section>
                    <p>以下の図のように、ROC曲線と等損失直線が接している部分が選択すべき動作点となる</p>
                    <img src="6.jpg" width="480px">
                </section>
			</div>

		</div>

		<script src="../lib/js/head.min.js"></script>
		<script src="../js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: '../lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: '../plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: '../plugin/math/math.js', async: true },
					{ src: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML', async: true }
				]
			});
			Reveal.addEventListener( 'slidechanged', function( event ) {
				MathJax.Hub.Rerender(event.currentSlide);
				// if (event.indexh == 4 && event.indexv == 5) {
				// 	// Reveal.configure({ center: false });
				// } else {
				// 	Reveal.configure({ center: true });
				// }
			} );
		</script>

	</body>
</html>
